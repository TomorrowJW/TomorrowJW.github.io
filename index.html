<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="description" content="Jiesheng Wu&#39;s home page">
    <link rel="shortcut icon" href="./images/logo-ahnu.jpeg">
    <link rel="stylesheet" href="./assets/jemdoc.css" type="text/css">
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-88572407-1', 'auto');
      ga('send', 'pageview');
    </script>
    <meta name="google-site-verification" content="F0Q0t5oLq1pGwXGMf_38oA2MxW_zfiMRsQTYD4_GJoQ"/>
    <title>Jiesheng Wu</title>
  </head>

  <body>
    <div id="layout-content" style="margin-top:1.5em">
      <table>
        <tbody>
          <tr>
            <td width="78%">
              <div id="toptitle">
                <h1>Jiesheng Wu (å´æ°èƒœ)&nbsp;</h1>
              </div>
              <p>
		I am a lecturer at the <a href="https://ci.ahnu.edu.cn/">School of Computer and Information</a>, <a href="https://www.ahnu.edu.cn/">Anhui Normal University</a>.
Previously, I received my Ph.D. in Engineering from Nankai University in June 2024. My research focuses on computer vision and multi-modal intelligence,
especially RGB/RGB-Depth/RGB-Thermal/RGB-Depth-Thermal/Underwater/Collaborative/High-Resolution/Remote Sensing Salient Object Detection,
RGB/RGB-D/Plant/Crop/Collaborative Camouflaged Object Detection, RGB-Thermal Image Segmentation,
Dichotomous Image Segmentation, Multi-modal Large Language Model for Visual Tasks,
Medical Image Segmentation (e.g. Polyp Segmentation, Ultrasound Image Segmentation, PET-CT Lung Tumor Segmentation)
and a series of binary image segmentation tasks (e.g. Surface Defect Detection, Road Extraction), etc.
             <br><br>
<div style="color: black;">
</div>
</p>
<h3 style="padding-top:0em"></h3>
              <object id="object" data="assets/envelope.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="mailto:jasonwu@ahnu.edu.cn">jasonwu[AT]ahnu.edu.cn</a>
              &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
              <object id="object" data="assets/scholar.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="https://scholar.google.com/citations?user=fDgrxRcAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a>
              &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
              <object id="object" data="assets/github.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="https://github.com/TomorrowJW?tab=repositories" target="_blank">GitHub</a>
            </td>
            <td>
              <img src="./images/love2.jpeg" border="0" width="80%" style="max-height:150px; object-fit: cover;">
            </td>
          </tr>
        </tbody>
      </table>
	  
<p><br><br> <!-- ä¸¤è¡Œç©ºç™½ -->
  <p><strong style="color: red;">ğŸ“¢ ç°æ‹›æ”¶ç¡•å£«ç ”ç©¶ç”Ÿ1-2åï¼Œæ¬¢è¿é‚®ä»¶ä¸æˆ‘è”ç³»ï¼</strong><br>
  è¯·é™„ä¸Šä½ çš„ <strong style="color: red;">ç®€å†å’Œæˆç»©å•</strong>ã€‚æ­¤å¤–ï¼Œéå¸¸æ¬¢è¿å¯¹ <strong style="color: red;">äººå·¥æ™ºèƒ½ç®—æ³•</strong> æ„Ÿå…´è¶£ã€æƒ³ä¿ç ”ã€æƒ³è€ƒç ”ã€æƒ³å­¦ä¹ 
	  çš„æœ¬ç§‘ç”Ÿï¼ˆæœ€å¥½æ˜¯ç†å·¥ç§‘ä¸“ä¸šï¼‰ä¸æˆ‘è”ç³»ï¼</p>
  <hr>
</p>
  
  <p><strong style="color: red;">ğŸŒŸ æœ¬ç§‘ç”Ÿä¹Ÿèƒ½åšç§‘ç ”ï¼</strong><br>
  åšç§‘ç ”ä»æ¥ä¸æ˜¯ç ”ç©¶ç”Ÿçš„ä¸“åˆ©ï¼Œæœ¬ç§‘ç”ŸåŒæ ·å¯ä»¥å‚ä¸ç§‘ç ”ã€‚<br>
  å¦‚æœä½ åœ¨æœ¬ç§‘é˜¶æ®µå°±èƒ½å‘è¡¨ <strong style="color: red;">é«˜è´¨é‡å­¦æœ¯è®ºæ–‡</strong>ï¼Œå®Œå…¨æœ‰æœºä¼š <strong style="color: red;">ç›´æ¥ç”³è¯·æµ·å¤–åæ ¡çš„ç¡•å£«æˆ–åšå£«å°±è¯»</strong>ã€‚</p>

  <hr>

  <p><strong style="color: red;">ğŸ‘¨â€ğŸ« æˆ‘ä¼šäº²è‡ªæŒ‡å¯¼ä½ ï¼š</strong></p>
<ul>
  <li>å­¦ä¹ æ–¹æ³•ä¸æ–¹å‘</li>
  <li>ä»£ç å®è·µä¸é¡¹ç›®</li>
  <li>å­¦æœ¯è®ºæ–‡å†™ä½œä¸æŠ•ç¨¿</li>
  <li>å­¦ç§‘ç«èµ›ç­‰æ´»åŠ¨</li>
</ul>


  <p>æˆ‘å¥‰è¡Œã€Œ<strong style="color: red;">ä¸€èµ·åŠªåŠ›ã€ä¸€èµ·å¥‹æ–—</strong>ã€çš„å›¢é˜Ÿæ°›å›´ï¼Œ<br>
  å¯¹ <strong style="color: red;">å‘è¡¨é«˜è´¨é‡ç§‘ç ”è®ºæ–‡</strong> çš„åŒå­¦ï¼Œå°†ç»™äºˆä¸€å®šå¥–åŠ±ï¼ˆå¦‚å¥–é‡‘ã€èšé¤ç­‰ï¼‰ï¼Œä¹Ÿæ”¯æŒç»§ç»­æƒ³è¯»åšçš„åŒå­¦æ·±é€ è¯»åšï¼</p>

  <hr>

  <p style="color:blue; font-weight:bold;">
    ğŸ—£ ä¸€å¥è¯æ€»ç»“ï¼š<strong>ä¸ç”»é¥¼ï¼å¸ˆç”Ÿç»„é˜Ÿæ•´å¤§æ´»ï¼ŒCä½è®ºæ–‡ä¸€èµ·é£ï¼</strong>
  </p>

  <hr>

  <p><strong style="color: red;">ğŸˆ æˆ‘çš„é£æ ¼æ˜¯è¿™æ ·çš„ï¼š</strong></p>
  <ul>
    <li>æ€§æ ¼éšå’Œï¼Œä¹äºä¸å­¦ç”Ÿäº¤æµ</li>
    <li>ä¸å¼ºPushï¼Œä½†é¼“åŠ±å­¦ç”Ÿè‡ªå¾‹ä¸Šè¿›</li>
    <li>æœ€çœ‹é‡ä½ æ˜¯å¦å…·å¤‡ <strong style="color: red;">ç‹¬ç«‹æ€è€ƒçš„èƒ½åŠ›</strong></li>
    <li>ä¼šå¯¹è‡ªå·±å°Pushä¸€æŠŠ</li>
    <li>è‹¥ä½ å­¦ç´¯äº†ï¼Œæˆ‘æ”¯æŒä½ ã€Œå°å°èººå¹³ã€ä¸€ä¼šå„¿</li>
  </ul>
  <p>æˆ‘ä¸æ˜¯ä¸šå†…æœ€é¡¶å°–çš„å­¦è€…ï¼Œä½†æˆ‘æœ‰ä¸€ç‚¹å°å°æ¢¦æƒ³ï¼Œ<br>
  å¹³æ—¶å–œæ¬¢å†å²ã€æ¯›é€‰ï¼Œä¹Ÿä¼šåˆ·åˆ·æŠ–éŸ³ã€å°çº¢ä¹¦ï¼Œäº†è§£00åçš„ç²¾ç¥ä¸–ç•Œï½</p>

  <hr>

  <p><strong style="color: red;">â¤ï¸ æ— è®ºä½ æœªæ¥çš„è·¯åœ¨å“ªï¼Œæˆ‘éƒ½æ”¯æŒä½ ï¼</strong><br>
  å¦‚æœä½ æ‰“ç®—èµ°å·¥ä¸šç•Œã€è€ƒå…¬ã€è€ƒç¼–ç­‰ç­‰ï¼Œåªè¦ä½ ä¸è™šåº¦å…‰é˜´ï¼Œå°±æ˜¯å¥½å­¦ç”Ÿï¼<br>
  ä¾‹å¦‚æ¯å¤©åšæŒè·‘ä¸‰å…¬é‡Œä¹Ÿå¾ˆæ£’ â€”â€” <strong style="color: red;">èº«ä½“å’Œå­¦ä¹ ï¼Œæ€»è¦æœ‰ä¸€ä¸ªåœ¨è·¯ä¸Šï¼</strong></p>

  <hr>

  <p><strong style="color: red;">ğŸ“Œ ä¸å¥½å¯¹å­¦ç”Ÿæœ‰ä»€ä¹ˆå»ºè®®ï¼Œæ¯•ç«Ÿæˆ‘ä¹Ÿåˆšæ¯•ä¸šæ²¡å¤šä¹…ï¼Œåªæœ‰ä¸‰ä¸ªæœŸæœ›ï¼š</strong></p>
  <ol>
    <li>é”»ç‚¼å¥½èº«ä½“</li>
    <li>ä¿æŒç§¯æä¹è§‚çš„å¿ƒæ€ã€æ‡‚æ„Ÿæ©ï¼Œçœ‹ä¸­å¸ˆç”Ÿæƒ…ï¼</li>
    <li>å­¦ä¹ çŸ¥è¯†ï¼Œæ‹“å±•æ€ç»´è¾¹ç•Œï¼</li>
  </ol>

  <p>æˆ‘è¡·å¿ƒç¥æ„¿æˆ‘çš„å­¦ç”Ÿèµ°å¾—æ›´é«˜æ›´è¿œï¼Œæ¥è§¦æ›´å¤šä¼˜ç§€çš„äººï¼<br>
  <strong style="color: red;">å¸Œæœ›æˆ‘çš„å­¦ç”Ÿå°†æ¥æ¯”æˆ‘æ›´ä¼˜ç§€ï¼Œæˆ‘ä¼šä¸ºä½ æ„Ÿåˆ°æ— æ¯”å¼€å¿ƒï¼</strong></p>
  
      <!-- Selected Publications -->
      <h2>Selected Publications</h2>

      <ul>
        <div style="font-size: 0.8em">
          <strong>Notes:</strong> Joint first authors are indicated using # and corresponding authors are indicated using *.
        </div>

        <h3> 2025 </h3>
		<li>
          <p>
            <b>Shift the Lens: Environment-Aware Unsupervised Camouflaged Object Detection</b><br>
            Ji Du, Fangwei Hao, Mingyang Yu, Desheng Kong, <strong>Jiesheng Wu</strong>, Bin Wang, Jing Xu*, Ping Li*<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2025 (CCF æ¨èAç±»è§†è§‰é¡¶ä¼š)<br>
            [PDF]
            [Code]
            [Official Version]
          </p>
		  
        <h3> 2024 </h3>
        <li>
          <p>
            <b>Transformer Fusion and Pixel-Level Contrastive Learning for RGB-D Salient Object Detection</b><br>
            <strong>Jiesheng Wu</strong>, Fangwei Hao, Weiyun Liang, and Jing Xu*<br>
            <i>IEEE Transactions on Multimedia (TMM)</i>, 2024 (ä¸­ç§‘é™¢ä¸€åŒºå¤šåª’ä½“é¡¶åˆŠï¼ŒCAAI æ¨èAç±»é¡¶åˆŠï¼ŒCCF æ¨èBç±»å¤šåª’ä½“é¡¶åˆŠ)<br>
            <a href="https://Tomorrowjw.github.io//papers/[TMM2024]Transformer_Fusion_and_Pixel-Level_Contrastive_Learning_for_RGB-D_Salient_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/TomorrowJW/TPCL_RGBDSOD">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/10122979">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Weighted Dense Semantic Aggregation and Explicit Boundary Modeling for Camouflaged Object Detection</b><br>
            Weiyun Liang, <strong>Jiesheng Wu</strong>, Xinyue Mu, Fangwei Hao, Ji Du, Jing Xu*<br>
            <i> IEEE Sensors Journal </i>, 2024 (ä¸­ç§‘é™¢äºŒåŒºæœŸåˆŠ)<br>
            <a href="https://Tomorrowjw.github.io//papers/[SJ2024]Weighted_Dense_Semantic_Aggregation_and_Explicit_Boundary_Modeling_for_Camouflaged_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/crrcoo/SAE-Net">[Code]</a>
			<a href="https://ieeexplore.ieee.org/document/10537109">[Official Version]</a>
          </p>
        </li>
		<li>
          <p>
            <b>Lightweight blueprint residual network for single image super-resolution</b><br>
            Fangwei Hao, <strong>Jiesheng Wu</strong>, Weiyun Liang, Jing Xu*, Ping Li<br>
            <i> Expert Systems with Applications (ESWA) </i>, 2024 (ä¸­ç§‘é™¢ä¸€åŒºæœŸåˆŠ, CCF æ¨èCç±»æœŸåˆŠ)<br>
            <a href="https://Tomorrowjw.github.io//papers/[ESWA2024]Lightweight_blueprint_residual_network_for_single_image_super-resolution.pdf">[PDF]</a>
            [Code]
			<a href="https://www.sciencedirect.com/science/article/pii/S0957417424008200">[Official Version]</a>
          </p>
        </li>

		
        <h3> 2023 </h3>
		<li>
          <p>
            <b>FAClue: Exploring Frequency Clues by Adaptive Frequency-Attention for Deepfake Detection</b><br>
            Weiyun Liang, Yanfeng Wu, <strong>Jiesheng Wu</strong>, and Jing Xu*<br>
            <i>42nd Chinese Control Conference (CCC)</i>, 2023 (EIä¼šè®®, å›½å†…è‡ªåŠ¨åŒ–é¡¶çº§ä¼šè®®)<br>
            <a href="https://Tomorrowjw.github.io//papers/[CCC2023]FAClue_Exploring_Frequency_Clues_by_Adaptive_Frequency-Attention_for_Deepfake_Detection.pdf">[PDF]</a>
            [Code]
            <a href="https://ieeexplore.ieee.org/document/10240940">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>FINet: Frequency Injection Network for Lightweight Camouflaged Object Detection</b><br>
            Weiyun Liang#, <strong>Jiesheng Wu#</strong>, Yanfeng Wu, Xinyue Mu, and Jing Xu*<br>
            <i>IEEE Signal Processing Letters (IEEE SPL)</i>, 2023 (ä¸­ç§‘é™¢äºŒåŒºæœŸåˆŠ, CCF æ¨èCç±»æœŸåˆŠ)<br>
            <a href="https://Tomorrowjw.github.io//papers/[SPL2023]FINet_Frequency_Injection_Network_for_Lightweight_Camouflaged_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/crrcoo/FINet">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/10409558">[Official Version]</a>
          </p>
        </li>
		<li>
          <p>
            <b>Mask-and-Edge Co-Guided Separable Network for Camouflaged Object Detection</b><br>
            <strong>Jiesheng Wu</strong>, Weiyun Liang, Fangwei Hao, and Jing Xu*<br>
            <i>IEEE Signal Processing Letters (IEEE SPL)</i>, 2023  (ä¸­ç§‘é™¢äºŒåŒºæœŸåˆŠ, CCF æ¨èCç±»æœŸåˆŠ)<br>
            <a href="https://Tomorrowjw.github.io//papers/[SPL2023]Mask-and-Edge_Co-Guided_Separable_Network_for_Camouflaged_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/TomorrowJW/MECS-Net-COD">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/10163250">[Official Version]</a>
          </p>
        </li>

        <h3> 2022 </h3>
        <li>
          <p>
            <b>Hglnet: A Generic Hierarchical Global-Local Feature Fusion Network for Multi-modal Classification</b><br>
            <strong>Jiesheng Wu</strong>, Junan Zhao, and Jing Xu*<br>
            <i>IEEE International Conference on Multimedia and Expo (ICME)</i>, 2022 (CCF æ¨èBç±»å¤šåª’ä½“æ——èˆ°ä¼šè®®)<br>
            <a href="https://Tomorrowjw.github.io//papers/[ICME2022]HGLNET_A_Generic_Hierarchical_Global-Local_Feature_Fusion_Network_for_Multi-Modal_Classification.pdf">[PDF]</a>
            [Code]
            <a href="https://ieeexplore.ieee.org/document/9859834">[Official Version]</a>
          </p>
        </li>
		<li>
          <p>
            <b>Visual Sentiment Classification via Low-Rank Regularization and Label Relaxation</b><br>
            Xiao Jin, Peiguang Jin, <strong>Jiesheng Wu</strong>, Jing Xu*, and Yuting Su<br>
            <i>IEEE Transactions on Cognitive and Developmental Systems (TCDS)</i>, 2022 (ä¸­ç§‘é™¢ä¸‰åŒºæœŸåˆŠ)<br>
            <a href="https://Tomorrowjw.github.io//papers/[TCDS2022]Visual_Sentiment_Classification_via_Low-Rank_Regularization_and_Label_Relaxation.pdf">[PDF]</a>
            [Code]
            <a href="https://ieeexplore.ieee.org/document/9658319">[Official Version]</a>
          </p>
        </li>

      <div id="footer">
        <div id="footer-text">Â© Jiesheng Wu</div>
      </div>

    </div>
  </body>
</html>
