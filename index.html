<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="description" content="Jiesheng Wu&#39;s home page">
    <link rel="shortcut icon" href="./images/logo-ahnu.jpeg">
    <link rel="stylesheet" href="./assets/jemdoc.css" type="text/css">
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-88572407-1', 'auto');
      ga('send', 'pageview');
    </script>
    <meta name="google-site-verification" content="F0Q0t5oLq1pGwXGMf_38oA2MxW_zfiMRsQTYD4_GJoQ"/>
    <title>Jiesheng Wu</title>
  </head>

  <body>
    <div id="layout-content" style="margin-top:1.5em">
      <table>
        <tbody>
          <tr>
            <td width="78%">
              <div id="toptitle">
                <h1>Jiesheng Wu (吴杰胜)&nbsp;</h1>
              </div>
              <p>
		I am a lecturer at the <a href="https://ci.ahnu.edu.cn/">School of Computer and Information</a>, <a href="https://www.ahnu.edu.cn/">Anhui Normal University</a>.
Previously, I received my Ph.D. in Engineering from Nankai University in June 2024. My research focuses on computer vision and multi-modal intelligence,
especially RGB/RGB-Depth/RGB-Thermal/RGB-Depth-Thermal/Underwater/Collaborative/High-Resolution/Remote Sensing Salient Object Detection,
RGB/RGB-D/Plant/Crop/Collaborative Camouflaged Object Detection, RGB-Thermal Image Segmentation,
Dichotomous Image Segmentation, Multi-modal Large Language Model for Visual Tasks,
Medical Image Segmentation (e.g. Polyp Segmentation, Ultrasound Image Segmentation, PET-CT Lung Tumor Segmentation)
and a series of binary image segmentation tasks (e.g. Surface Defect Detection, Road Extraction), etc.
             <br><br>
<div style="color: black;">
</div>
</p>
<h3 style="padding-top:0em"></h3>
              <object id="object" data="assets/envelope.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="mailto:jasonwu@ahnu.edu.cn">jasonwu[AT]ahnu.edu.cn</a>
              &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
              <object id="object" data="assets/scholar.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="https://scholar.google.com/citations?user=fDgrxRcAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a>
              &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
              <object id="object" data="assets/github.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="https://github.com/TomorrowJW?tab=repositories" target="_blank">GitHub</a>
            </td>
            <td>
              <img src="./images/love2.jpeg" border="0" width="80%" style="max-height:150px; object-fit: cover;">
            </td>
          </tr>
        </tbody>
      </table>
	  
<p><br><br> <!-- 两行空白 -->
  <p><strong style="color: red;">📢 现招收硕士研究生1-2名，欢迎邮件与我联系！</strong><br>
  请附上你的 <strong style="color: red;">简历和成绩单</strong>。此外，非常欢迎对 <strong style="color: red;">人工智能算法</strong> 感兴趣、想保研、想考研、想学习
	  的本科生（最好是理工科专业）与我联系！</p>
  <hr>
</p>
  
  <p><strong style="color: red;">🌟 本科生也能做科研！</strong><br>
  做科研从来不是研究生的专利，本科生同样可以参与科研。<br>
  如果你在本科阶段就能发表 <strong style="color: red;">高质量学术论文</strong>，完全有机会 <strong style="color: red;">直接申请海外名校的硕士或博士就读</strong>。</p>

  <hr>

  <p><strong style="color: red;">👨‍🏫 我会亲自指导你：</strong></p>
<ul>
  <li>学习方法与方向</li>
  <li>代码实践与项目</li>
  <li>学术论文写作与投稿</li>
  <li>学科竞赛等活动</li>
</ul>


  <p>我奉行「<strong style="color: red;">一起努力、一起奋斗</strong>」的团队氛围，<br>
  对 <strong style="color: red;">发表高质量科研论文</strong> 的同学，将给予一定奖励（如奖金、聚餐等），也支持继续想读博的同学深造读博！</p>

  <hr>

  <p style="color:blue; font-weight:bold;">
    🗣 一句话总结：<strong>不画饼！师生组队整大活，C位论文一起飞！</strong>
  </p>

  <hr>

  <p><strong style="color: red;">🎈 我的风格是这样的：</strong></p>
  <ul>
    <li>性格随和，乐于与学生交流</li>
    <li>不强Push，但鼓励学生自律上进</li>
    <li>最看重你是否具备 <strong style="color: red;">独立思考的能力</strong></li>
    <li>会对自己小Push一把</li>
    <li>若你学累了，我支持你「小小躺平」一会儿</li>
  </ul>
  <p>我不是业内最顶尖的学者，但我有一点小小梦想，<br>
  平时喜欢历史、毛选，也会刷刷抖音、小红书，了解00后的精神世界～</p>

  <hr>

  <p><strong style="color: red;">❤️ 无论你未来的路在哪，我都支持你！</strong><br>
  如果你打算走工业界、考公、考编等等，只要你不虚度光阴，就是好学生！<br>
  例如每天坚持跑三公里也很棒 —— <strong style="color: red;">身体和学习，总要有一个在路上！</strong></p>

  <hr>

  <p><strong style="color: red;">📌 不好对学生有什么建议，毕竟我也刚毕业没多久，只有三个期望：</strong></p>
  <ol>
    <li>锻炼好身体</li>
    <li>保持积极乐观的心态、懂感恩，看中师生情！</li>
    <li>学习知识，拓展思维边界！</li>
  </ol>

  <p>我衷心祝愿我的学生走得更高更远，接触更多优秀的人！<br>
  <strong style="color: red;">希望我的学生将来比我更优秀，我会为你感到无比开心！</strong></p>
  
      <!-- Selected Publications -->
      <h2>Selected Publications</h2>

      <ul>
        <div style="font-size: 0.8em">
          <strong>Notes:</strong> Joint first authors are indicated using # and corresponding authors are indicated using *.
        </div>

        <h3> 2025 </h3>
		<li>
          <p>
            <b>Shift the Lens: Environment-Aware Unsupervised Camouflaged Object Detection</b><br>
            Ji Du, Fangwei Hao, Mingyang Yu, Desheng Kong, <strong>Jiesheng Wu</strong>, Bin Wang, Jing Xu*, Ping Li*<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2025 (CCF 推荐A类视觉顶会)<br>
            [PDF]
            [Code]
            [Official Version]
          </p>
		  
        <h3> 2024 </h3>
        <li>
          <p>
            <b>Transformer Fusion and Pixel-Level Contrastive Learning for RGB-D Salient Object Detection</b><br>
            <strong>Jiesheng Wu</strong>, Fangwei Hao, Weiyun Liang, and Jing Xu*<br>
            <i>IEEE Transactions on Multimedia (TMM)</i>, 2024 (中科院一区多媒体顶刊，CAAI 推荐A类顶刊，CCF 推荐B类多媒体顶刊)<br>
            <a href="https://Tomorrowjw.github.io//papers/[TMM2024]Transformer_Fusion_and_Pixel-Level_Contrastive_Learning_for_RGB-D_Salient_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/TomorrowJW/TPCL_RGBDSOD">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/10122979">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Weighted Dense Semantic Aggregation and Explicit Boundary Modeling for Camouflaged Object Detection</b><br>
            Weiyun Liang, <strong>Jiesheng Wu</strong>, Xinyue Mu, Fangwei Hao, Ji Du, Jing Xu*<br>
            <i> IEEE Sensors Journal </i>, 2024 (中科院二区期刊)<br>
            <a href="https://Tomorrowjw.github.io//papers/[SJ2024]Weighted_Dense_Semantic_Aggregation_and_Explicit_Boundary_Modeling_for_Camouflaged_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/crrcoo/SAE-Net">[Code]</a>
			<a href="https://ieeexplore.ieee.org/document/10537109">[Official Version]</a>
          </p>
        </li>
		<li>
          <p>
            <b>Lightweight blueprint residual network for single image super-resolution</b><br>
            Fangwei Hao, <strong>Jiesheng Wu</strong>, Weiyun Liang, Jing Xu*, Ping Li<br>
            <i> Expert Systems with Applications (ESWA) </i>, 2024 (中科院一区期刊, CCF 推荐C类期刊)<br>
            <a href="https://Tomorrowjw.github.io//papers/[ESWA2024]Lightweight_blueprint_residual_network_for_single_image_super-resolution.pdf">[PDF]</a>
            [Code]
			<a href="https://www.sciencedirect.com/science/article/pii/S0957417424008200">[Official Version]</a>
          </p>
        </li>

		
        <h3> 2023 </h3>
		<li>
          <p>
            <b>FAClue: Exploring Frequency Clues by Adaptive Frequency-Attention for Deepfake Detection</b><br>
            Weiyun Liang, Yanfeng Wu, <strong>Jiesheng Wu</strong>, and Jing Xu*<br>
            <i>42nd Chinese Control Conference (CCC)</i>, 2023 (EI会议, 国内自动化顶级会议)<br>
            <a href="https://Tomorrowjw.github.io//papers/[CCC2023]FAClue_Exploring_Frequency_Clues_by_Adaptive_Frequency-Attention_for_Deepfake_Detection.pdf">[PDF]</a>
            [Code]
            <a href="https://ieeexplore.ieee.org/document/10240940">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>FINet: Frequency Injection Network for Lightweight Camouflaged Object Detection</b><br>
            Weiyun Liang#, <strong>Jiesheng Wu#</strong>, Yanfeng Wu, Xinyue Mu, and Jing Xu*<br>
            <i>IEEE Signal Processing Letters (IEEE SPL)</i>, 2023 (中科院二区期刊, CCF 推荐C类期刊)<br>
            <a href="https://Tomorrowjw.github.io//papers/[SPL2023]FINet_Frequency_Injection_Network_for_Lightweight_Camouflaged_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/crrcoo/FINet">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/10409558">[Official Version]</a>
          </p>
        </li>
		<li>
          <p>
            <b>Mask-and-Edge Co-Guided Separable Network for Camouflaged Object Detection</b><br>
            <strong>Jiesheng Wu</strong>, Weiyun Liang, Fangwei Hao, and Jing Xu*<br>
            <i>IEEE Signal Processing Letters (IEEE SPL)</i>, 2023  (中科院二区期刊, CCF 推荐C类期刊)<br>
            <a href="https://Tomorrowjw.github.io//papers/[SPL2023]Mask-and-Edge_Co-Guided_Separable_Network_for_Camouflaged_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/TomorrowJW/MECS-Net-COD">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/10163250">[Official Version]</a>
          </p>
        </li>

        <h3> 2022 </h3>
        <li>
          <p>
            <b>Hglnet: A Generic Hierarchical Global-Local Feature Fusion Network for Multi-modal Classification</b><br>
            <strong>Jiesheng Wu</strong>, Junan Zhao, and Jing Xu*<br>
            <i>IEEE International Conference on Multimedia and Expo (ICME)</i>, 2022 (CCF 推荐B类多媒体旗舰会议)<br>
            <a href="https://Tomorrowjw.github.io//papers/[ICME2022]HGLNET_A_Generic_Hierarchical_Global-Local_Feature_Fusion_Network_for_Multi-Modal_Classification.pdf">[PDF]</a>
            [Code]
            <a href="https://ieeexplore.ieee.org/document/9859834">[Official Version]</a>
          </p>
        </li>
		<li>
          <p>
            <b>Visual Sentiment Classification via Low-Rank Regularization and Label Relaxation</b><br>
            Xiao Jin, Peiguang Jin, <strong>Jiesheng Wu</strong>, Jing Xu*, and Yuting Su<br>
            <i>IEEE Transactions on Cognitive and Developmental Systems (TCDS)</i>, 2022 (中科院三区期刊)<br>
            <a href="https://Tomorrowjw.github.io//papers/[TCDS2022]Visual_Sentiment_Classification_via_Low-Rank_Regularization_and_Label_Relaxation.pdf">[PDF]</a>
            [Code]
            <a href="https://ieeexplore.ieee.org/document/9658319">[Official Version]</a>
          </p>
        </li>

      <div id="footer">
        <div id="footer-text">© Jiesheng Wu</div>
      </div>

    </div>
  </body>
</html>
