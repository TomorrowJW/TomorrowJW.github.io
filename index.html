<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="description" content="Jiesheng Wu&#39;s home page">
    <link rel="shortcut icon" href="./images/logo-ahnu.jpeg">
    <link rel="stylesheet" href="./assets/jemdoc.css" type="text/css">
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-88572407-1', 'auto');
      ga('send', 'pageview');
    </script>
    <meta name="google-site-verification" content="F0Q0t5oLq1pGwXGMf_38oA2MxW_zfiMRsQTYD4_GJoQ"/>
    <title>Jiesheng Wu</title>
  </head>

  <body>
    <div id="layout-content" style="margin-top:1.5em">
      <table>
        <tbody>
          <tr>
            <td width="78%">
              <div id="toptitle">
                <h1>Jiesheng Wu (å´æ°èƒœ)&nbsp;</h1>
              </div>
              <p>
		I am a lecturer at the <a href="https://ci.ahnu.edu.cn/">School of Computer and Information</a>, <a href="https://www.ahnu.edu.cn/">Anhui Normal University</a>.
I was born in March 1996. Previously, I received my Ph.D. in Engineering from <a href="https://www.nankai.edu.cn/">Nankai University</a> in June 2024. My research focuses on Computer Vision and Multi-modal Intelligence,
especially RGB/RGB-Depth/RGB-Thermal/RGB-Depth-Thermal/Underwater/Collaborative/High-Resolution/Remote Sensing Salient Object Detection,
RGB/RGB-D/Plant/Crop/Collaborative Camouflaged Object Detection, RGB-Thermal Image Segmentation,
Dichotomous Image Segmentation, Multi-modal Large Language Model for Visual Tasks,
Medical Image Segmentation (e.g. Polyp Segmentation, Ultrasound Image Segmentation, PET-CT Lung Tumor Segmentation)
and a series of binary image segmentation tasks (e.g. Surface Defect Detection, Road Extraction), etc.
             <br><br>
<div style="color: black;">
</div>
</p>
<p>
  æˆ‘æ˜¯<a href="https://www.ahnu.edu.cn/">å®‰å¾½å¸ˆèŒƒå¤§å­¦</a> <a href="https://ci.ahnu.edu.cn/">è®¡ç®—æœºä¸ä¿¡æ¯å­¦é™¢</a>çš„è®²å¸ˆã€‚
  æˆ‘å‡ºç”Ÿäº1996å¹´3æœˆï¼Œ2024å¹´6æœˆè·å¾—<a href="https://www.nankai.edu.cn/">å—å¼€å¤§å­¦</a>äººå·¥æ™ºèƒ½ä¸“ä¸šå·¥å­¦åšå£«å­¦ä½ã€‚
  æˆ‘çš„ç ”ç©¶æ–¹å‘åŒ…æ‹¬è®¡ç®—æœºè§†è§‰ä¸å¤šæ¨¡æ€æ™ºèƒ½ï¼Œç‰¹åˆ«æ˜¯RGB/RGB-Depth/RGB-Thermal/RGB-Depth-Thermal/æ°´ä¸‹/ååŒ/é«˜åˆ†è¾¨ç‡/é¥æ„Ÿæ˜¾è‘—æ€§ç›®æ ‡æ£€æµ‹ï¼Œ
  RGB/RGB-Depth/æ¤ç‰©/å†œä½œç‰©/ååŒä¼ªè£…ç›®æ ‡æ£€æµ‹ï¼ŒRGB-Thermalå›¾åƒåˆ†å‰²ï¼Œé«˜ç²¾åº¦å›¾åƒåˆ†å‰²ï¼Œ
  å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹è§†è§‰ä»»åŠ¡ã€åŒ»å­¦å›¾åƒåˆ†å‰²ï¼ˆå¦‚æ¯è‚‰åˆ†å‰²ã€è¶…å£°å›¾åƒåˆ†å‰²ã€PET-CTè‚ºéƒ¨è‚¿ç˜¤åˆ†å‰²ï¼‰ï¼Œ
  ä»¥åŠä¸€ç³»åˆ—äºŒå€¼å›¾åƒåˆ†å‰²ä»»åŠ¡ï¼ˆå¦‚è¡¨é¢ç¼ºé™·æ£€æµ‹ã€é“è·¯æå–ï¼‰ç­‰ã€‚
 <br><br>
<div style="color: black;">
</div>
</p>
<h3 style="padding-top:0em"></h3>
              <object id="object" data="assets/envelope.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="mailto:jasonwu@ahnu.edu.cn">jasonwu[AT]ahnu.edu.cn</a>
              &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
              <object id="object" data="assets/scholar.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="https://scholar.google.com/citations?user=fDgrxRcAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a>
              &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
              <object id="object" data="assets/github.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="https://github.com/TomorrowJW?tab=repositories" target="_blank">GitHub</a>
            </td>
            <td>
              <img src="./images/love2.jpeg" border="0" width="80%" style="max-height:150px; object-fit: cover;">
            </td>
          </tr>
        </tbody>
      </table>
	  
<p><br><br> <!-- ä¸¤è¡Œç©ºç™½ --></p>

<p><strong style="color: red;">ğŸ“¢ ç°æ‹›æ”¶ç¡•å£«ç ”ç©¶ç”Ÿ1-2åï¼Œæ¬¢è¿é‚®ä»¶ä¸æˆ‘è”ç³»ï¼(å·²åŸºæœ¬ç¡®è®¤åé¢ï¼Œä¸ç”¨å†è”ç³»äº†ï¼Œä¸è¿‡å¯ä»¥äº¤æµå­¦ä¹ ï¼Œæˆ–è€…æœ¬ç§‘ç”Ÿè”ç³»ï¼)</strong></p>

<p><strong style="color: green;">
ğŸ“¢ å¯¹äºç¡•å£«ç ”ç©¶ç”Ÿæ‹›ç”Ÿï¼Œæˆ‘ä¸çœ‹é‡å‡ºèº«å’Œå­¦å†ï¼Œæ›´çœ‹é‡æ€åº¦ä¸åŠªåŠ›ã€‚<br>
æœ‰å¥è¯è¯´å¾—å¥½ï¼šâ€œç§ä¸€æ£µæ ‘æœ€å¥½çš„æ—¶é—´æ˜¯åå¹´å‰ï¼Œå…¶æ¬¡æ˜¯ç°åœ¨ã€‚â€<br>
æœ¬äººæ¬¢è¿æœ‰å¼ºçƒˆå­¦ä¹ æ„æ„¿ã€åšå®šæ±‚å­¦æ„æ„¿çš„åŒå­¦è”ç³»ã€‚<br>
åªè¦æ„¿æ„ä»˜å‡ºã€è„šè¸å®åœ°å»åšï¼Œå°±æ°¸è¿œä¸æ™šã€‚åŠªåŠ›è¦è½åˆ°è¡ŒåŠ¨ä¸Šï¼Œè€Œä¸æ˜¯åœç•™åœ¨å£å¤´ä¸Šï¼
</strong></p>
<!--
<p style="color:blue; font-weight:bold;">
  ğŸ—£ <strong>å¯¹äºç¡•å£«æ‹›ç”Ÿï¼Œæœ¬äººæ¬¢è¿æœ‰å¼ºçƒˆå­¦ä¹ æ„æ„¿ã€åšå®šæ±‚å­¦æ„æ„¿çš„åŒå­¦è”ç³»ï¼Œä¹Ÿæ•¬è¯·â€œåªæ˜¯æƒ³æ‹¿ä¸ªç¡•å£«å­¦å†ã€å”¯åŠŸåˆ©ã€éšå¤§æµâ€çš„åŒå­¦å‹¿æ‰°ï¼</strong>
</p>
-->
<p>è¯·é™„ä¸Šä½ çš„ <strong style="color: red;">ç®€å†å’Œæˆç»©å•</strong>ã€‚æ­¤å¤–ï¼Œéå¸¸æ¬¢è¿å¯¹ <strong style="color: red;">äººå·¥æ™ºèƒ½ç®—æ³•</strong> æ„Ÿå…´è¶£ã€æƒ³ä¿ç ”ã€æƒ³è€ƒç ”ã€æƒ³å­¦ä¹  çš„æœ¬ç§‘ç”Ÿï¼ˆæœ€å¥½æ˜¯ç†å·¥ç§‘ä¸“ä¸šï¼‰ä¸æˆ‘è”ç³»ï¼</p>

<hr>

<p><strong style="color: red;">ğŸŒŸ æœ¬ç§‘ç”Ÿä¹Ÿèƒ½åšç§‘ç ”ï¼</strong><br>
åšç§‘ç ”ä»æ¥ä¸æ˜¯ç ”ç©¶ç”Ÿçš„ä¸“åˆ©ï¼Œæœ¬ç§‘ç”ŸåŒæ ·å¯ä»¥å‚ä¸ç§‘ç ”ã€‚<br>
å¦‚æœä½ åœ¨æœ¬ç§‘é˜¶æ®µå°±èƒ½å‘è¡¨ <strong style="color: red;">é«˜è´¨é‡å­¦æœ¯è®ºæ–‡</strong>ï¼Œå®Œå…¨æœ‰æœºä¼š <strong style="color: red;">ç›´æ¥ç”³è¯·æµ·å¤–åæ ¡çš„ç¡•å£«æˆ–åšå£«å°±è¯»</strong>ã€‚</p>

<hr>

<p><strong style="color: red;">ğŸ‘¨â€ğŸ« æˆ‘ä¼šäº²è‡ªæŒ‡å¯¼ä½ ï¼Œä¸ä¼šè®©ä½ ä¸€ä¸ªäººå•ç‹¬æï¼Œæˆ‘ä¹Ÿä¼šåŠªåŠ›ï¼š</strong></p>
<ul>
  <li>å­¦ä¹ æ–¹æ³•ä¸æ–¹å‘</li>
  <li>ä»£ç å®è·µä¸é¡¹ç›®</li>
  <li>å¦‚ä½•åšç§‘ç ”</li>
  <li>å­¦æœ¯è®ºæ–‡å†™ä½œä¸æŠ•ç¨¿</li>
  <li>å­¦ç§‘ç«èµ›ç­‰æ´»åŠ¨</li>
</ul>

<p>æˆ‘å¥‰è¡Œã€Œ<strong style="color: red;">ä¸€èµ·åŠªåŠ›ã€ä¸€èµ·å¥‹æ–—</strong>ã€çš„å›¢é˜Ÿæ°›å›´ï¼Œ<br>
å¯¹ <strong style="color: red;">å‘è¡¨é«˜è´¨é‡ç§‘ç ”è®ºæ–‡</strong> çš„åŒå­¦ï¼Œå°†ç»™äºˆä¸€å®šå¥–åŠ±ï¼ˆå¦‚å¥–é‡‘ã€èšé¤ç­‰ï¼‰ï¼Œä¹Ÿæ”¯æŒç»§ç»­æƒ³è¯»åšçš„åŒå­¦æ·±é€ è¯»åšï¼</p>

<hr>

<p style="color:blue; font-weight:bold;">
  ğŸ—£ ä¸€å¥è¯æ€»ç»“ï¼š<strong>ä¸ç”»é¥¼ï¼å¸ˆç”Ÿç»„é˜Ÿæ•´å¤§æ´»ï¼ŒCä½è®ºæ–‡ä¸€èµ·é£ï¼</strong>
</p>

<hr>

<p><strong style="color: red;">ğŸˆ æˆ‘çš„é£æ ¼æ˜¯è¿™æ ·çš„ï¼š</strong></p>
<ul>
  <li>æ€§æ ¼éšå’Œï¼Œä¹äºä¸å­¦ç”Ÿäº¤æµ</li>
  <li>ä¸å¼ºPushï¼Œä½†é¼“åŠ±å­¦ç”Ÿè‡ªå¾‹ä¸Šè¿›</li>
  <li>æœ€çœ‹é‡ä½ æ˜¯å¦å…·å¤‡ <strong style="color: red;">ç‹¬ç«‹æ€è€ƒçš„èƒ½åŠ›</strong></li>
  <li><strong style="color: blue;">æˆ‘ä¸éœ€è¦å­¦ç”Ÿå®Œå…¨ç¬¦åˆè§„èŒƒçš„å›ç­”ï¼Œè€Œæ˜¯è¦çœ‹åˆ°ä½ èƒ½æœ‰åˆ›æ–°çš„æ€è·¯å’Œå·®å¼‚åŒ–çš„åšæ³•</strong></li>
  <li>ä¼šå¯¹è‡ªå·±å°Pushä¸€æŠŠ</li>
  <li>è‹¥ä½ å­¦ç´¯äº†ï¼Œæˆ‘æ”¯æŒä½ ã€Œå°å°èººå¹³ã€ä¸€ä¼šå„¿</li>
</ul>

<p>æˆ‘ä¸æ˜¯ä¸šå†…æœ€é¡¶å°–çš„å­¦è€…ï¼Œç§‘ç ”æå¾—ä¸€èˆ¬ï¼Œä½†æˆ‘æœ‰ä¸€ç‚¹å°å°çš„æ¢¦æƒ³ï¼Œ<br>
å¹³æ—¶å–œæ¬¢çœ‹å†å²ã€è¯»æ¯›é€‰ï¼Œä¹Ÿä¼šåˆ·åˆ·æŠ–éŸ³ã€å°çº¢ä¹¦ï¼Œäº†è§£00åçš„ç²¾ç¥ä¸–ç•Œï½</p>

<hr>

<p><strong style="color: red;">â¤ï¸ æ— è®ºä½ æœªæ¥çš„è·¯åœ¨å“ªï¼Œæˆ‘éƒ½æ”¯æŒä½ ï¼</strong><br>
å¦‚æœä½ æ‰“ç®—èµ°å·¥ä¸šç•Œã€è€ƒå…¬ã€è€ƒç¼–ç­‰ç­‰ï¼Œåªè¦ä½ ä¸è™šåº¦å…‰é˜´ï¼Œå°±æ˜¯å¥½å­¦ç”Ÿï¼<br>
ä¾‹å¦‚æ¯å¤©åšæŒè·‘ä¸‰å…¬é‡Œä¹Ÿå¾ˆæ£’ â€”â€” <strong style="color: red;">èº«ä½“å’Œå­¦ä¹ ï¼Œæ€»è¦æœ‰ä¸€ä¸ªåœ¨è·¯ä¸Šï¼</strong></p>

<hr>

<p><strong style="color: red;">ğŸ“Œ ä¸å¥½å¯¹å­¦ç”Ÿæœ‰ä»€ä¹ˆå»ºè®®ï¼Œæ¯•ç«Ÿæˆ‘ä¹Ÿåˆšæ¯•ä¸šæ²¡å¤šä¹…ï¼Œåªæœ‰ä¸‰ä¸ªæœŸæœ›ï¼š</strong></p>
<ol>
  <li>é”»ç‚¼å¥½èº«ä½“</li>
  <li>ä¿æŒç§¯æä¹è§‚çš„å¿ƒæ€ã€æ‡‚æ„Ÿæ©ï¼Œ<span style="color:green; font-weight:bold;">çœ‹ä¸­å¸ˆç”Ÿæƒ…</span>ï¼<span style="color:green; font-weight:bold;">å‡¡äº‹ä¸èƒ½åªè€ƒè™‘è‡ªå·±ï¼Œå¸ˆç”Ÿæƒ…æ˜¯ç¬¬ä¸€çš„ï¼Œå¿ƒæ€€æ„Ÿæ©ï¼Œæ‰èƒ½èµ°çš„è¶Šè¿œï¼</span>ï¼</li>
  <li>å­¦ä¹ çŸ¥è¯†ï¼Œæ‹“å±•æ€ç»´è¾¹ç•Œï¼</li>
</ol>

<p>æˆ‘è¡·å¿ƒç¥æ„¿æˆ‘çš„å­¦ç”Ÿèµ°å¾—æ›´é«˜æ›´è¿œï¼Œæ¥è§¦æ›´å¤šä¼˜ç§€çš„äººï¼<br>
<strong style="color: red;">å¸Œæœ›æˆ‘çš„å­¦ç”Ÿå°†æ¥æ¯”æˆ‘æ›´ä¼˜ç§€ï¼Œæˆ‘ä¼šä¸ºä½ æ„Ÿåˆ°æ— æ¯”å¼€å¿ƒï¼</strong></p>

  
      <!-- Selected Publications -->
      <h2>Selected Publications</h2>

      <ul>
        <div style="font-size: 0.8em">
          <strong>Notes:</strong> Joint first authors are indicated using # and corresponding authors are indicated using *.
        </div>

        <h3> 2025 </h3>
		<li>
          <p>
            <b>Shift the Lens: Environment-Aware Unsupervised Camouflaged Object Detection</b><br>
            Ji Du, Fangwei Hao, Mingyang Yu, Desheng Kong, <strong>Jiesheng Wu</strong>, Bin Wang, Jing Xu*, Ping Li*<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2025 (CCF æ¨èAç±»è§†è§‰é¡¶ä¼š)<br>
            [PDF]
            [Code]
            [Official Version]
          </p>
	</li>
        <li>
          <p>
            <b>Depth-Assisted Mamba with Adapter Tuning for Rail Surface Defect Detection</b><br>
            Jiankang Hong, Xun Yang, Luojun Lin, <strong>Jiesheng Wu*</strong>, and Ye Luo<br>
            <i> IEEE Transactions on Circuits and Systems for Video Technology </i>, 2025 (Under Review)<br>
        [PDF]
        [Code]
	[Official Version]
          </p>
        </li>
	<li>
          <p>
            <b>Boosting Foreground-Background Disentanglement for Camouflaged Object Detection</b><br>
            <strong>Jiesheng Wu</strong>, Fangwei Hao, Jing Xu*, Ping Li<br>
            <i> ACM Transactions on Multimedia Computing, Communications, and Applications (TOMM) </i>, 2025 (Under Review)<br>
            [PDF]
            [Code]
	    [Official Version]
          </p>
        </li>
	<li>
          <p>
            <b>RA-COD: Retrieval-Augmented Camouflaged Object Detection</b><br>
            Ji Du, <strong>Jiesheng Wu*</strong>, Desheng Kong, Fangwei Hao, Jing Xu, and Ping Li.<br>
            <i> IEEE Transactions on Image Processing (TIP) </i>, 2025 (Under Review)<br>
            [PDF]
            [Code]
	    [Official Version]
          </p>
        </li>
	<li>
          <p>
            <b>UpGen: Unleashing Potential of Foundation Models for Training-Free Camouflage Detection via Generative Mode</b><br>
            Ji Du, <strong>Jiesheng Wu*</strong>, Desheng Kong, Weiyun Liang, Fangwei Hao, Jing Xu, Bin Wang, Guiling Wang, and Ping Li.<br>
            <i> IEEE Transactions on Image Processing (TIP) </i>, 2025 (Under Review)<br>
            [PDF]
            [Code]
	    [Official Version]
          </p>
        </li>
		  
        <h3> 2024 </h3>
        <li>
          <p>
            <b>Transformer Fusion and Pixel-Level Contrastive Learning for RGB-D Salient Object Detection</b><br>
            <strong>Jiesheng Wu</strong>, Fangwei Hao, Weiyun Liang, and Jing Xu*<br>
            <i>IEEE Transactions on Multimedia (TMM)</i>, 2024 (ä¸­ç§‘é™¢ä¸€åŒºå¤šåª’ä½“é¡¶åˆŠï¼ŒCAAI æ¨èAç±»é¡¶åˆŠï¼ŒCCF æ¨èBç±»å¤šåª’ä½“é¡¶åˆŠ)<br>
            <a href="https://Tomorrowjw.github.io//papers/[TMM2024]Transformer_Fusion_and_Pixel-Level_Contrastive_Learning_for_RGB-D_Salient_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/TomorrowJW/TPCL_RGBDSOD">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/10122979">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Weighted Dense Semantic Aggregation and Explicit Boundary Modeling for Camouflaged Object Detection</b><br>
            Weiyun Liang, <strong>Jiesheng Wu</strong>, Xinyue Mu, Fangwei Hao, Ji Du, Jing Xu*<br>
            <i> IEEE Sensors Journal </i>, 2024 (ä¸­ç§‘é™¢äºŒåŒºæœŸåˆŠ)<br>
            <a href="https://Tomorrowjw.github.io//papers/[SJ2024]Weighted_Dense_Semantic_Aggregation_and_Explicit_Boundary_Modeling_for_Camouflaged_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/crrcoo/SAE-Net">[Code]</a>
			<a href="https://ieeexplore.ieee.org/document/10537109">[Official Version]</a>
          </p>
        </li>
		<li>
          <p>
            <b>Lightweight blueprint residual network for single image super-resolution</b><br>
            Fangwei Hao, <strong>Jiesheng Wu</strong>, Weiyun Liang, Jing Xu*, Ping Li<br>
            <i> Expert Systems with Applications (ESWA) </i>, 2024 (ä¸­ç§‘é™¢ä¸€åŒºæœŸåˆŠ, CCF æ¨èCç±»æœŸåˆŠ)<br>
            <a href="https://Tomorrowjw.github.io//papers/[ESWA2024]Lightweight_blueprint_residual_network_for_single_image_super-resolution.pdf">[PDF]</a>
            [Code]
			<a href="https://www.sciencedirect.com/science/article/pii/S0957417424008200">[Official Version]</a>
          </p>
        </li>

		
        <h3> 2023 </h3>
		<li>
          <p>
            <b>FAClue: Exploring Frequency Clues by Adaptive Frequency-Attention for Deepfake Detection</b><br>
            Weiyun Liang, Yanfeng Wu, <strong>Jiesheng Wu</strong>, and Jing Xu*<br>
            <i>42nd Chinese Control Conference (CCC)</i>, 2023 (EIä¼šè®®, å›½å†…è‡ªåŠ¨åŒ–é¡¶çº§ä¼šè®®)<br>
            <a href="https://Tomorrowjw.github.io//papers/[CCC2023]FAClue_Exploring_Frequency_Clues_by_Adaptive_Frequency-Attention_for_Deepfake_Detection.pdf">[PDF]</a>
            [Code]
            <a href="https://ieeexplore.ieee.org/document/10240940">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>FINet: Frequency Injection Network for Lightweight Camouflaged Object Detection</b><br>
            Weiyun Liang#, <strong>Jiesheng Wu#</strong>, Yanfeng Wu, Xinyue Mu, and Jing Xu*<br>
            <i>IEEE Signal Processing Letters (IEEE SPL)</i>, 2023 (ä¸­ç§‘é™¢äºŒåŒºæœŸåˆŠ, CCF æ¨èCç±»æœŸåˆŠ)<br>
            <a href="https://Tomorrowjw.github.io//papers/[SPL2023]FINet_Frequency_Injection_Network_for_Lightweight_Camouflaged_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/crrcoo/FINet">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/10409558">[Official Version]</a>
          </p>
        </li>
		<li>
          <p>
            <b>Mask-and-Edge Co-Guided Separable Network for Camouflaged Object Detection</b><br>
            <strong>Jiesheng Wu</strong>, Weiyun Liang, Fangwei Hao, and Jing Xu*<br>
            <i>IEEE Signal Processing Letters (IEEE SPL)</i>, 2023  (ä¸­ç§‘é™¢äºŒåŒºæœŸåˆŠ, CCF æ¨èCç±»æœŸåˆŠ)<br>
            <a href="https://Tomorrowjw.github.io//papers/[SPL2023]Mask-and-Edge_Co-Guided_Separable_Network_for_Camouflaged_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/TomorrowJW/MECS-Net-COD">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/10163250">[Official Version]</a>
          </p>
        </li>

        <h3> 2022 </h3>
        <li>
          <p>
            <b>Hglnet: A Generic Hierarchical Global-Local Feature Fusion Network for Multi-modal Classification</b><br>
            <strong>Jiesheng Wu</strong>, Junan Zhao, and Jing Xu*<br>
            <i>IEEE International Conference on Multimedia and Expo (ICME)</i>, 2022 (CCF æ¨èBç±»å¤šåª’ä½“æ——èˆ°ä¼šè®®)<br>
            <a href="https://Tomorrowjw.github.io//papers/[ICME2022]HGLNET_A_Generic_Hierarchical_Global-Local_Feature_Fusion_Network_for_Multi-Modal_Classification.pdf">[PDF]</a>
            [Code]
            <a href="https://ieeexplore.ieee.org/document/9859834">[Official Version]</a>
          </p>
        </li>
		<li>
          <p>
            <b>Visual Sentiment Classification via Low-Rank Regularization and Label Relaxation</b><br>
            Xiao Jin, Peiguang Jin, <strong>Jiesheng Wu</strong>, Jing Xu*, and Yuting Su<br>
            <i>IEEE Transactions on Cognitive and Developmental Systems (TCDS)</i>, 2022 (ä¸­ç§‘é™¢ä¸‰åŒºæœŸåˆŠ)<br>
            <a href="https://Tomorrowjw.github.io//papers/[TCDS2022]Visual_Sentiment_Classification_via_Low-Rank_Regularization_and_Label_Relaxation.pdf">[PDF]</a>
            [Code]
            <a href="https://ieeexplore.ieee.org/document/9658319">[Official Version]</a>
          </p>
        </li>

      <div id="footer">
        <div id="footer-text">Â© Jiesheng Wu</div>
      </div>

    </div>
  </body>
</html>
<!-- ä¸è’œå­ç»Ÿè®¡ -->
<span id="busuanzi_container_site_pv" style="font-size:14px;">
  æœ¬ç«™æ€»è®¿é—®é‡ï¼š<span id="busuanzi_value_site_pv"></span> æ¬¡
</span> |
<span id="busuanzi_container_site_uv" style="font-size:14px;">
  æœ¬ç«™è®¿å®¢æ•°ï¼š<span id="busuanzi_value_site_uv"></span> äºº
</span>

<!-- å¼•å…¥ä¸è’œå­ç»Ÿè®¡è„šæœ¬ -->
<script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

