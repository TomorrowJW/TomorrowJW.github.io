<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="description" content="Jiesheng Wu&#39;s home page">
    <link rel="shortcut icon" href="./images/logo-ahnu.jpeg">
    <link rel="stylesheet" href="./assets/jemdoc.css" type="text/css">
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-88572407-1', 'auto');
      ga('send', 'pageview');
    </script>
    <meta name="google-site-verification" content="F0Q0t5oLq1pGwXGMf_38oA2MxW_zfiMRsQTYD4_GJoQ"/>
    <title>Jiesheng Wu</title>
  </head>

  <body>
    <div id="layout-content" style="margin-top:1.5em">
      <table>
        <tbody>
          <tr>
            <td width="78%">
              <div id="toptitle">
                <h1>Jiesheng Wu &nbsp;</h1>
              </div>
              <p>
                I am a lecturer at the <a href="https://www.ahnu.edu.cn/">School of Computer and Information</a>, <a href="https://ci.ahnu.edu.cn/">Anhui Normal University</a>.
                Previously, I obtained both my Ph.D degree from <a href="https://ai.nankai.edu.cn/">Nankai University</a> in 2024.
                My research focuses on computer vision and multimodal intelligence, 
				especially RGB/RGB-Depth/RGB-Thermal/RGB-Depth-Thermal/Underwater/Collaborative/High-Resolution/Remote Sensing Salient Object Detection, 
				RGB/RGB-D/Plant/Crop/Collaborative Camouflaged Object Detection, RGB-Thermal Image Segmentation, 
				Dichotomous Image Segmentation, Multi-modal Large Language Model for Vison Tasks, 
				Medical Image Segmentation (e.g., Polyp Segmentation, Ultrasound Image Segmentation, PET-CT Lung Cancer Segmentation) 
				and A range of binary image segmentation tasks (e.g., Surface Defect Detection, Road Extraction).

                <br><br>
				<font color="red">
					现招收硕士研究生1-2名，欢迎邮件与我联系。此外，非常欢迎想学习、想保研、想读研、想做AI算法的本科生与我联系，
					做科研从来不是研究生的专利，本科生也可以同样做科研，若在本科阶段发了高质量学术论文，可以直接申请海外名校的硕士或者博士就读。
					我会亲自指导学习方法、路线、代码、学术论文写作和投稿等等，也欢迎想参加学科竞赛的同学联系我，我奉行的是一起努力，一起奋斗，
					我会对致力于发表高质量科研论文的同学给予一定的奖励，同时支持想读博的同学继续深造读博，愿你我一起努力！
					<span style="color:blue; font-weight:bold;">
						一句话就是：不画饼，奶茶管够肝开心！师生组队整大活，C位论文一起飞！
						当然，这些的前提是有一个积极乐观的心态、有一个好的身体，所以假如你的目标是毕业后不搞科研而是进入工业界或者考公考编，我也支持，
						只要不是虚度光阴，就是好学生。假如你每天坚持跑三公里我也觉得你很棒！
					</span>
					但是读研的三年里重点还是锻炼好身体、学习知识、拓展思维边界！
					我衷心祝愿我的学生能走的更高更远，去接触更多优秀的人！
				</font>

                <!-- <br><br>
                <font color="red">I am looking for motivated PhD students (co-supervised with <a href="https://personal.ntu.edu.sg/exdjiang/">Prof. Xudong Jiang</a> at NTU) and interns to work on image, video, and point cloud recognition problems.
                Scholarships are available [<a href="https://www.a-star.edu.sg/Scholarships/for-graduate-studies/singapore-international-graduate-award-singa">link</a>].
                Drop me an email if you are interested.</font> -->
              </p>
              <h3 style="padding-top:-0.32em"></h3>
              <object id="object" data="assets/envelope.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="mailto:jasonwu@ahnu.edu.cn">jasonwu [AT] ahnu.edu.cn</a>
              &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
              <object id="object" data="assets/scholar.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="https://scholar.google.com/citations?user=fDgrxRcAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a>
              &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;
              <object id="object" data="assets/github.svg" width="15" height="15" type="image/svg+xml"></object> &nbsp;
              <a href="https://github.com/TomorrowJW?tab=repositories" target="_blank">GitHub</a>
            </td>
            <td>
              <img src="./images/love2.jpeg" border="0" width="100%">
            </td>
          </tr>
        </tbody>
      </table>

      <!-- Selected Publications -->
      <h2>Selected Publications</h2>

      <ul>
        <div style="font-size: 0.8em">
          <strong>Notes:</strong> Joint first authors are indicated using # and corresponding authors are indicated using *.
        </div>

        <h3> 2025 </h3>
		<li>
          <p>
            <b>Shift the Lens: Environment-Aware Unsupervised Camouflaged Object Detection</b><br>
            Ji Du, Fangwei Hao, Mingyang Yu, Desheng Kong, <strong>Jiesheng Wu</strong>, Bin Wang, Jing Xu*, Ping Li*<br>
            <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 2025 (CCF 推荐A类视觉顶会)<br>
            [PDF]
            [Code]
            [Official Version]
          </p>
		  
        <h3> 2024 </h3>
        <li>
          <p>
            <b>Transformer Fusion and Pixel-Level Contrastive Learning for RGB-D Salient Object Detection</b><br>
            <strong>Jiesheng Wu</strong>, Fangwei Hao, Weiyun Liang, and Jing Xu*<br>
            <i>IEEE Transactions on Multimedia (TMM)</i>, 2024 (中科院一区多媒体顶刊，CAAI 推荐A类顶刊，CCF 推荐B类多媒体顶刊)<br>
            <a href="https://Tomorrowjw.github.io//papers/[TMM2024]Transformer_Fusion_and_Pixel-Level_Contrastive_Learning_for_RGB-D_Salient_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/TomorrowJW/TPCL_RGBDSOD">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/10122979">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>Weighted Dense Semantic Aggregation and Explicit Boundary Modeling for Camouflaged Object Detection</b><br>
            Weiyun Liang, <strong>Jiesheng Wu</strong>, Xinyue Mu, Fangwei Hao, Ji Du, Jing Xu*<br>
            <i> IEEE Sensors Journal </i>, 2024 (中科院二区期刊)<br>
            <a href="https://Tomorrowjw.github.io//papers/[SJ2024]Weighted_Dense_Semantic_Aggregation_and_Explicit_Boundary_Modeling_for_Camouflaged_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/crrcoo/SAE-Net">[Code]</a>
			<a href="https://ieeexplore.ieee.org/document/10537109">[Official Version]</a>
          </p>
        </li>
		<li>
          <p>
            <b>Lightweight blueprint residual network for single image super-resolution</b><br>
            Fangwei Hao, <strong>Jiesheng Wu</strong>, Weiyun Liang, Jing Xu*, Ping Li<br>
            <i> Expert Systems with Applications (ESWA) </i>, 2024 (中科院一区期刊, CCF 推荐C类期刊)<br>
            <a href="https://Tomorrowjw.github.io//papers/[ESWA2024]Lightweight_blueprint_residual_network_for_single_image_super-resolution.pdf">[PDF]</a>
            [Code]
			<a href="https://www.sciencedirect.com/science/article/pii/S0957417424008200">[Official Version]</a>
          </p>
        </li>

		
        <h3> 2023 </h3>
		<li>
          <p>
            <b>FAClue: Exploring Frequency Clues by Adaptive Frequency-Attention for Deepfake Detection</b><br>
            Weiyun Liang, Yanfeng Wu, <strong>Jiesheng Wu</strong>, and Jing Xu*<br>
            <i>42nd Chinese Control Conference (CCC)</i>, 2023 (EI会议, 国内自动化顶级会议)<br>
            <a href="https://Tomorrowjw.github.io//papers/[CCC2023]FAClue_Exploring_Frequency_Clues_by_Adaptive_Frequency-Attention_for_Deepfake_Detection.pdf">[PDF]</a>
            [Code]
            <a href="https://ieeexplore.ieee.org/document/10240940">[Official Version]</a>
          </p>
        </li>
        <li>
          <p>
            <b>FINet: Frequency Injection Network for Lightweight Camouflaged Object Detection</b><br>
            Weiyun Liang#, <strong>Jiesheng Wu#</strong>, Yanfeng Wu, Xinyue Mu, and Jing Xu*<br>
            <i>IEEE Signal Processing Letters (IEEE SPL)</i>, 2023 (中科院二区期刊, CCF 推荐C类期刊)<br>
            <a href="https://Tomorrowjw.github.io//papers/[SPL2023]FINet_Frequency_Injection_Network_for_Lightweight_Camouflaged_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/crrcoo/FINet">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/10409558">[Official Version]</a>
          </p>
        </li>
		<li>
          <p>
            <b>Mask-and-Edge Co-Guided Separable Network for Camouflaged Object Detection</b><br>
            <strong>Jiesheng Wu</strong>, Weiyun Liang, Fangwei Hao, and Jing Xu*<br>
            <i>IEEE Signal Processing Letters (IEEE SPL)</i>, 2023  (中科院二区期刊, CCF 推荐C类期刊)<br>
            <a href="https://Tomorrowjw.github.io//papers/[SPL2023]Mask-and-Edge_Co-Guided_Separable_Network_for_Camouflaged_Object_Detection.pdf">[PDF]</a>
            <a href="https://github.com/TomorrowJW/MECS-Net-COD">[Code]</a>
            <a href="https://ieeexplore.ieee.org/document/10163250">[Official Version]</a>
          </p>
        </li>

        <h3> 2022 </h3>
        <li>
          <p>
            <b>Hglnet: A Generic Hierarchical Global-Local Feature Fusion Network for Multi-modal Classification</b><br>
            <strong>Jiesheng Wu</strong>, Junan Zhao, and Jing Xu*<br>
            <i>IEEE International Conference on Multimedia and Expo (ICME)</i>, 2022 (CCF 推荐B类多媒体旗舰会议)<br>
            <a href="https://Tomorrowjw.github.io//papers/[ICME2022]HGLNET_A_Generic_Hierarchical_Global-Local_Feature_Fusion_Network_for_Multi-Modal_Classification.pdf">[PDF]</a>
            [Code]
            <a href="https://ieeexplore.ieee.org/document/9859834">[Official Version]</a>
          </p>
        </li>
		<li>
          <p>
            <b>Visual Sentiment Classification via Low-Rank Regularization and Label Relaxation</b><br>
            Xiao Jin, Peiguang Jin, <strong>Jiesheng Wu</strong>, Jing Xu*, and Yuting Su<br>
            <i>IEEE Transactions on Cognitive and Developmental Systems (TCDS)</i>, 2022 (中科院三区期刊)<br>
            <a href="https://Tomorrowjw.github.io//papers/[TCDS2022]Visual_Sentiment_Classification_via_Low-Rank_Regularization_and_Label_Relaxation.pdf">[PDF]</a>
            [Code]
            <a href="https://ieeexplore.ieee.org/document/9658319">[Official Version]</a>
          </p>
        </li>

      <div id="footer">
        <div id="footer-text">© Jiesheng Wu</div>
      </div>

    </div>
  </body>
</html>
